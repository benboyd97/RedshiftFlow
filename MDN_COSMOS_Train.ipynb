{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMZBruFvWLst"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/Ben_Boyd_MSc_Project/Data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OuM_kDUPrCG"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt # creating visualizations\n",
        "import numpy as onp # we still need original nump for some tasks\n",
        "\n",
        "\n",
        "from matplotlib import cm\n",
        "from matplotlib.ticker import LinearLocator\n",
        "\n",
        "# using stax, much cleaner\n",
        "from jax.experimental import stax\n",
        "from jax.scipy.special import logsumexp #def generate_data(n_samples): Compute the log of the sum of exponentials of input elements\n",
        "from jax.nn import softmax # pretty much the same as the interface as the one in scipy.special\n",
        "\n",
        "from jax.experimental.stax import (Dense, Tanh, Flatten, Relu, LogSoftmax, Softmax, Exp,Sigmoid,Softplus,LeakyRelu)\n",
        "\n",
        "import jax.numpy as np # JAX is supposed to have an API that closely resemble NumPy's\n",
        "from jax import grad, jit, vmap, value_and_grad\n",
        "from jax import random\n",
        "import jax.nn as nn\n",
        "\n",
        "from astropy.table import Table\n",
        "\n",
        "from astropy import table\n",
        "from astropy.io import fits,ascii,votable\n",
        "from astropy import units as u \n",
        "from astropy import constants as const\n",
        "from astropy import table\n",
        "from astropy.cosmology import Planck15,FlatLambdaCDM\n",
        "import copy\n",
        "from jax.experimental import optimizers\n",
        "from scipy.stats import norm\n",
        "key = random.PRNGKey(777)\n",
        "\n",
        "def sigma68(pred,real):\n",
        "  sorted=onp.sort((pred-real)/(1+real))\n",
        "  return 0.5*(sorted[int(0.841*len(pred))]-sorted[int(0.159*len(pred))])\n",
        "\n",
        "def outlier_frac(pred,real):\n",
        "  return len(pred[np.absolute((pred-real)/(1+real))>0.15])/len(pred)\n",
        "\n",
        "\n",
        "def bias(pred,real):\n",
        "  return np.median((pred-real)/(1+real))\n",
        "\n",
        "def plot_func(fun,pred,real,bins,zlim):\n",
        "  bin_edges=onp.linspace(0,zlim,bins+1)\n",
        "  vals=onp.array([])\n",
        "  for i in range(bins):\n",
        "    logic= onp.logical_and(real>bin_edges[i],real<bin_edges[i+1])\n",
        "    vals=onp.append(vals,fun(pred[logic],real[logic]))\n",
        "  width=bin_edges[1]-bin_edges[0]\n",
        "  plot=plt.plot(-width*0.5+bin_edges[1:],vals)\n",
        "  plt.xlabel('True Redshift',fontsize=16)\n",
        "  plt.xticks(fontsize=14)\n",
        "  plt.yticks(fontsize=14)\n",
        "  return plot\n",
        "\n",
        "n_mixture = 3\n",
        "batch_size=100000\n",
        "epochs=10000\n",
        "n_input=22\n",
        "test_name='MDN_fewer_bands'\n",
        "\n",
        "# get output from network\n",
        "#init_fun, the_network = stax.serial(Dense(512), Relu,Dense(1024), Sigmoid,Dense(512), Relu,Dense(256),Relu,Dense(128), Relu,Dense(64), Relu,Dense(32),Relu, Dense(n_mixture*3))\n",
        "init_fun, the_network = stax.serial(Dense(512),Relu, Dense(2054),Relu,Dense(512),Sigmoid,Dense(n_mixture*3))\n",
        "#init_fun, the_network = stax.serial(Dense(256),Sigmoid, Dense(1024),Sigmoid,Dense(256),Sigmoid,Dense(n_mixture*3))\n",
        "logSqrtTwoPI = onp.log(onp.sqrt(2.0 * onp.pi))\n",
        "\n",
        "def lognormal(y, mean, logstd):\n",
        "  return -0.5 * ((y - mean) / np.exp(logstd)) ** 2 - logstd - logSqrtTwoPI\n",
        "\n",
        "def get_mdn_coef(output):\n",
        "  logmix, mean, logstd = output.split(3, axis=1)\n",
        "  logmix = nn.log_softmax(logmix)\n",
        "  mean=nn.sigmoid(mean)\n",
        "  return logmix, mean, logstd\n",
        "\n",
        "def mdn_loss_func(logmix, mean, logstd, y):\n",
        "  v = logmix + lognormal(y, mean, logstd)\n",
        "  v = logsumexp(v, axis=1)\n",
        "  return -np.mean(v)\n",
        "\n",
        "def loss_fn(params, inputs, targets):\n",
        "  \"\"\" MDN Loss function for training loop. \"\"\"\n",
        "  outputs = the_network(params, inputs)\n",
        "  logmix, mean, logstd = get_mdn_coef(outputs)\n",
        "  return mdn_loss_func(logmix, mean, logstd, targets)\n",
        "\n",
        "@jit\n",
        "def update(s,params, x, y, opt_state):\n",
        "    \"\"\" Perform a forward pass, calculate the MSE & perform a SGD step. \"\"\"\n",
        "    loss, grads = value_and_grad(loss_fn)(params, x, y)\n",
        "    opt_state = opt_update(s, grads, opt_state)\n",
        "    return get_params(opt_state), opt_state, loss\n",
        "\n",
        "def train(params, x_data, y_data, opt_state):\n",
        "  s=0\n",
        "  for epoch in range(epochs):\n",
        "    loss_tot=0\n",
        "    for b in range(int(len(y_data)/batch_size)):\n",
        "        params, opt_state, loss = update(s,params, x_data[b*batch_size:(b+1)*batch_size,:], y_data[b*batch_size:(b+1)*batch_size,:], opt_state)\n",
        "        loss_tot+=loss\n",
        "        s+=1\n",
        "    print('Epoch: ',epoch,' Loss: ', loss_tot/int(len(y_data)/batch_size))\n",
        "    if epoch % 500 ==0:\n",
        "      if epoch != 0:\n",
        "        np.save(test_name+'_params.npy',params,allow_pickle=True)\n",
        "  return params\n",
        "\n",
        "\n",
        "def gumbel_sample(x, axis=1):\n",
        "  z = onp.random.gumbel(loc=0, scale=1, size=x.shape)\n",
        "  return (onp.log(x) + z).argmax(axis=axis)\n",
        "\n",
        "\n",
        "\n",
        "def pit(true,pi_data,mu_data,std):\n",
        "  n,k=onp.shape(logmix)\n",
        "  pit_val=onp.zeros(n)\n",
        "  for x in range(k):\n",
        "    pit_val+=pi_data[:,x]*norm.cdf(true,mu_data[:,x],std[:,x])\n",
        "  return pit_val\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "def plot_pdf(pi,mu,sig,pred,true=None,zrange=6):\n",
        "  plt.figure(figsize=(12,10))\n",
        "  x=onp.linspace(0,zrange,100)\n",
        "  pdf=onp.zeros(100)\n",
        "  for i in range(len(mu)):\n",
        "      pdf+=pi[i]*stats.norm.pdf(x,mu[i],sig[i])\n",
        "  plt.plot(x,pdf,color='blue')\n",
        "  plt.plot([pred,pred],[0,onp.max(pdf)],color='blue')\n",
        "  plt.plot([true,true],[0,onp.max(pdf)],color='red')\n",
        "  plt.show()\n",
        "\n",
        "def minmax_fit_and_scale(X):\n",
        "  min = X.min(axis=0)\n",
        "  max = X.max(axis=0)\n",
        "  X_std = (X - min) / (max - min)\n",
        "  return X_std,min,max\n",
        "\n",
        "def minmax_scale(X,min,max):\n",
        "  return (X - min) / (max - min)\n",
        "\n",
        "def minmax_unscale(X,min,max):\n",
        "  return X * (max - min) + min\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSCml2N1PrCM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "n_samples =  20000000 # just use train everything in a batch\n",
        "beta=True\n",
        "small_range=False\n",
        "magnitudes=False\n",
        "a=0\n",
        "if beta:\n",
        "  a+=5\n",
        "\n",
        "x_data=onp.zeros((n_samples,54))\n",
        "y_data=onp.zeros(n_samples)\n",
        "\n",
        "cats=20\n",
        "\n",
        "def mag_err(flux_err,flux):\n",
        "    \n",
        "    return 1.09*flux_err/flux\n",
        "\n",
        "def mag(flux):\n",
        "    x=-2.5*onp.log10(flux) + 23.9 \n",
        "    x[onp.isnan(x)]=0\n",
        "    return x \n",
        "\n",
        "  \n",
        "for c in range(cats):\n",
        "    cat = table.Table.read('sim/mil'+str(c+1)+'_noisy_gal.fits',format='fits',hdu=1)\n",
        "    keys=cat.keys()\n",
        "    count=0\n",
        "    y_data[(c)*1000000:(c+1)*1000000]=cat['redshift']\n",
        "    for key_name in keys:\n",
        "\n",
        "        if key_name[len(key_name)-9:]=='BETA_FLUX':\n",
        "\n",
        "                \n",
        "            filt=key_name[:len(key_name)-10+a]\n",
        "\n",
        "            if magnitudes:\n",
        "\n",
        "              x_data[(c)*1000000:(c+1)*1000000,count]=mag(cat[filt+'_FLUX'])\n",
        "              x_data[(c)*1000000:(c+1)*1000000,count+1]=mag_err(cat[filt+'_FLUXERR'],cat[filt+'_FLUX'])\n",
        "            else:\n",
        "              x_data[(c)*1000000:(c+1)*1000000,count]=cat[filt+'_FLUX']\n",
        "              x_data[(c)*1000000:(c+1)*1000000,count+1]=cat[filt+'_FLUXERR']\n",
        "            \n",
        "            count+=2\n",
        "            \n",
        "            \n",
        "        \n",
        "    print(c)\n",
        "\n",
        "\n",
        "x_data = np.array(x_data.reshape(n_samples, 54))\n",
        "\n",
        "if n_input!=54:\n",
        "  x_data=x_data[:,:n_input]\n",
        "\n",
        "\n",
        "\n",
        "if small_range:\n",
        "  ids=np.logical_and(y_data>=0,y_data<=2)\n",
        "  y_data=y_data[ids]\n",
        "  x_data=x_data[ids,:]\n",
        "\n",
        "print(x_data)\n",
        "\n",
        "y_data = np.array(y_data.reshape(len(y_data), 1))/6\n",
        "\n",
        "cat=0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAF8nLk9XDsJ"
      },
      "outputs": [],
      "source": [
        "!pip install optax\n",
        "import optax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHM-6izdPrCO"
      },
      "outputs": [],
      "source": [
        "\n",
        "constant_scheduler = optax.constant_schedule(0.001)\n",
        "\n",
        "_, params = init_fun(key, (batch_size, n_input))\n",
        "opt_init, opt_update, get_params = optimizers.adam(constant_scheduler )\n",
        "opt_state = opt_init(params)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yMlf3LOpPrCR",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "params = train(params, x_data, y_data, opt_state)\n",
        "np.save(test_name+'_params.npy',params,allow_pickle=True)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "MDN_COSMOS_Train.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}