{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMZBruFvWLst"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import os\n",
        "os.chdir(\"drive/My Drive/Ben_Boyd_MSc_Project/Data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OuM_kDUPrCG"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt # creating visualizations\n",
        "import numpy as onp # we still need original nump for some tasks\n",
        "\n",
        "\n",
        "from matplotlib import cm\n",
        "from matplotlib.ticker import LinearLocator\n",
        "\n",
        "# using stax, much cleaner\n",
        "from jax.experimental import stax\n",
        "from jax.scipy.special import logsumexp #def generate_data(n_samples): Compute the log of the sum of exponentials of input elements\n",
        "from jax.nn import softmax # pretty much the same as the interface as the one in scipy.special\n",
        "\n",
        "from jax.experimental.stax import (Dense, Tanh, Flatten, Relu, LogSoftmax, Softmax, Exp,Sigmoid,Softplus,LeakyRelu)\n",
        "\n",
        "import jax.numpy as np # JAX is supposed to have an API that closely resemble NumPy's\n",
        "from jax import grad, jit, vmap, value_and_grad\n",
        "from jax import random\n",
        "import jax.nn as nn\n",
        "\n",
        "from astropy.table import Table\n",
        "\n",
        "from astropy import table\n",
        "from astropy.io import fits,ascii,votable\n",
        "from astropy import units as u \n",
        "from astropy import constants as const\n",
        "from astropy import table\n",
        "from astropy.cosmology import Planck15,FlatLambdaCDM\n",
        "import copy\n",
        "from jax.experimental import optimizers\n",
        "from scipy.stats import norm\n",
        "key = random.PRNGKey(123)\n",
        "\n",
        "def sigma68(pred,real):\n",
        "  sorted=onp.sort((pred-real)/(1+real))\n",
        "  return 0.5*(sorted[int(0.841*len(pred))-1]-sorted[int(0.159*len(pred))-1])\n",
        "\n",
        "\n",
        "def sigma_nmad(pred,real):\n",
        "\n",
        "  med=np.median(pred-real)\n",
        "\n",
        "  return 1.48*np.median(np.absolute(pred-real-med)/(1+real))\n",
        "\n",
        "def outlier_frac(pred,real):\n",
        "  return len(pred[np.absolute((pred-real)/(1+real))>0.15])/len(pred)\n",
        "\n",
        "\n",
        "def bias(pred,real):\n",
        "  return np.median((pred-real)/(1+real))\n",
        "\n",
        "def plot_func(fun,pred,real,bins,zlim,ax,color='blue',label=None):\n",
        "  bin_edges=onp.linspace(0,zlim,bins+1)\n",
        "  vals=onp.array([])\n",
        "  for i in range(bins):\n",
        "    logic= onp.logical_and(real>bin_edges[i],real<bin_edges[i+1])\n",
        "    vals=onp.append(vals,fun(pred[logic],real[logic]))\n",
        "  width=bin_edges[1]-bin_edges[0]\n",
        "\n",
        "  if ax==None:\n",
        "    plot=plt.plot(-width*0.5+bin_edges[1:],vals)\n",
        "    plt.xlabel('Spectroscopic Redshift',fontsize=16)\n",
        "    plt.xticks(fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "\n",
        "\n",
        "  else:\n",
        "    plot=ax.plot(-width*0.5+bin_edges[1:],vals,color=color,label=label)\n",
        "    ax.set_xlabel('Spectroscopic Redshift',fontsize=20)\n",
        "    for tick in ax.xaxis.get_major_ticks():\n",
        "      tick.label.set_fontsize(18) \n",
        "    for tick in ax.yaxis.get_major_ticks():\n",
        "      tick.label.set_fontsize(18) \n",
        "  return plot\n",
        "\n",
        "n_mixture = 3\n",
        "batch_size=100000\n",
        "epochs=10000\n",
        "n_input=54\n",
        "# get output from network\n",
        "#init_fun, the_network = stax.serial(Dense(512), Relu,Dense(1024), Sigmoid,Dense(512), Relu,Dense(256),Relu,Dense(128), Relu,Dense(64), Relu,Dense(32),Relu, Dense(n_mixture*3))\n",
        "init_fun, the_network = stax.serial(Dense(512),Relu, Dense(2048),Relu,Dense(512),Sigmoid,Dense(n_mixture*3))\n",
        "#init_fun, the_network = stax.serial(Dense(256),Sigmoid, Dense(1024),Sigmoid,Dense(256),Sigmoid,Dense(n_mixture*3))\n",
        "logSqrtTwoPI = onp.log(onp.sqrt(2.0 * onp.pi))\n",
        "\n",
        "def lognormal(y, mean, logstd):\n",
        "  return -0.5 * ((y - mean) / np.exp(logstd)) ** 2 - logstd - logSqrtTwoPI\n",
        "\n",
        "def get_mdn_coef(output):\n",
        "  logmix, mean, logstd = output.split(3, axis=1)\n",
        "  logmix = nn.log_softmax(logmix)\n",
        "  mean=nn.sigmoid(mean)\n",
        "  return logmix, mean, logstd\n",
        "\n",
        "def mdn_loss_func(logmix, mean, logstd, y):\n",
        "  v = logmix + lognormal(y, mean, logstd)\n",
        "  v = logsumexp(v, axis=1)\n",
        "  return -np.mean(v)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def loss_fn(params, inputs, targets):\n",
        "  \"\"\" MDN Loss function for training loop. \"\"\"\n",
        "  outputs = the_network(params, inputs)\n",
        "  logmix, mean, logstd = get_mdn_coef(outputs)\n",
        "  return mdn_loss_func(logmix, mean, logstd, targets)\n",
        "\n",
        "@jit\n",
        "def update(params, x, y, opt_state):\n",
        "    \"\"\" Perform a forward pass, calculate the MSE & perform a SGD step. \"\"\"\n",
        "    loss, grads = value_and_grad(loss_fn)(params, x, y)\n",
        "    opt_state = opt_update(0, grads, opt_state)\n",
        "    return get_params(opt_state), opt_state, loss\n",
        "\n",
        "def train(params, x_data, y_data, opt_state):\n",
        "  for epoch in range(epochs):\n",
        "    for b in range(int(len(y_data)/batch_size)):\n",
        "        params, opt_state, loss = update(params, x_data[b*batch_size:(b+1)*batch_size,:], y_data[b*batch_size:(b+1)*batch_size,:], opt_state)\n",
        "        print('Epoch: ',epoch,' Batch: ',b,' Loss: ', loss)\n",
        "    if epoch % 500 ==0:\n",
        "      if epoch != 0:\n",
        "        np.save(test_name+'_params_'+str(epoch)+'.npy',params,allow_pickle=True)\n",
        "  return params\n",
        "\n",
        "\n",
        "def gumbel_sample(x, axis=1):\n",
        "  z = onp.random.gumbel(loc=0, scale=1, size=x.shape)\n",
        "  return (onp.log(x) + z).argmax(axis=axis)\n",
        "\n",
        "\n",
        "\n",
        "def pit(true,pi_data,mu_data,std):\n",
        "  n,k=onp.shape(logmix)\n",
        "  pit_val=onp.zeros(n)\n",
        "  for x in range(k):\n",
        "    pit_val+=pi_data[:,x]*norm.cdf(true,mu_data[:,x],std[:,x])\n",
        "  return pit_val\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "def plot_pdf(pi,mu,sig,pred,true=None,zrange=6,ax=None):\n",
        "  x=onp.linspace(0,zrange,100)\n",
        "  pdf=onp.zeros(100)\n",
        "  for i in range(len(mu)):\n",
        "      pdf+=pi[i]*stats.norm.pdf(x,mu[i],sig[i])\n",
        "\n",
        "  if ax!=None:\n",
        "      plot=ax.plot(x,pdf,color='blue',label='PDF')\n",
        "      ax.plot([pred,pred],[0,onp.max(pdf)],color='blue',label=r'Photometric Redshift',linestyle='--')\n",
        "      ax.plot([true,true],[0,onp.max(pdf)],color='red',label=r'Spectroscopic Redshift')\n",
        "  else:\n",
        "    plot=plt.plot(x,pdf,color='blue')\n",
        "    plt.plot([pred,pred],[0,onp.max(pdf)],color='blue')\n",
        "    plt.plot([true,true],[0,onp.max(pdf)],color='red')\n",
        "\n",
        "  return plot\n",
        "\n",
        "def minmax_fit_and_scale(X):\n",
        "  min = X.min(axis=0)\n",
        "  max = X.max(axis=0)\n",
        "  X_std = (X - min) / (max - min)\n",
        "  return X_std,min,max\n",
        "\n",
        "def minmax_scale(X,min,max):\n",
        "  return (X - min) / (max - min)\n",
        "\n",
        "def minmax_unscale(X,min,max):\n",
        "  return X * (max - min) + min\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0WBGJqu6Eq8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEDfnZylVWuI"
      },
      "outputs": [],
      "source": [
        "#params=np.load('more_nodes_params_2001.npy',allow_pickle=True)\n",
        "#params=np.load('short_z_params_2000.npy',allow_pickle=True)\n",
        "params=np.load('three_newest_beta_params_2000.npy',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD5Gy3l4VkXW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "n_samples =  1000000 # just use train everything in a batch\n",
        "beta=True\n",
        "small_range=False\n",
        "magnitudes=False\n",
        "a=0\n",
        "if beta:\n",
        "  a+=5\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "cats=1\n",
        "\n",
        "def mag_err(flux_err,flux):\n",
        "    \n",
        "    return 1.09*flux_err/flux\n",
        "\n",
        "def mag(flux):\n",
        "    x=-2.5*onp.log10(flux) + 23.9 \n",
        "    x[onp.isnan(x)]=-2.5*onp.log10(-flux[onp.isnan(x)]) + 23.9 \n",
        "\n",
        "    return x \n",
        "filter_names=onp.array([])\n",
        "for c in range(cats):\n",
        "    cat = table.Table.read('sim/mil'+str(c+21)+'_noisy_gal.fits',format='fits',hdu=1)\n",
        "    if small_range:\n",
        "      cat=cat[cat['redshift']<2]\n",
        "    keys=cat.keys()\n",
        "    count=0\n",
        "    y_data=cat['redshift']\n",
        "    x_data=onp.zeros((len(y_data),54))\n",
        "    for key_name in keys:\n",
        "\n",
        "        if key_name[len(key_name)-9:]=='BETA_FLUX':\n",
        "\n",
        "                \n",
        "            filt=key_name[:len(key_name)-10+a]\n",
        "            filter_names=onp.append(filter_names,key_name[:len(key_name)-10])\n",
        "            if magnitudes:\n",
        "\n",
        "              x_data[:,count]=mag(cat[filt+'_FLUX'])\n",
        "              x_data[:,count+1]=mag_err(cat[filt+'_FLUXERR'],cat[filt+'_FLUX'])\n",
        "            else:\n",
        "              x_data[:,count]=cat[filt+'_FLUX']\n",
        "              x_data[:,count+1]=cat[filt+'_FLUXERR']\n",
        "            \n",
        "            count+=2\n",
        "            \n",
        "            \n",
        "        \n",
        "    print(c)\n",
        "\n",
        "\n",
        "x_data = np.array(x_data.reshape(len(x_data), n_input))\n",
        "\n",
        "\n",
        "print(x_data)\n",
        "\n",
        "y_data = np.array(y_data.reshape(len(y_data), 1))/6\n",
        "print(filter_names)\n",
        "#cat=0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnmOd0ICeQJ_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Alckg6MODgpg"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import math\n",
        "pi_symb=math.pi\n",
        "\n",
        "y_pred=onp.zeros(len(y_data))\n",
        "y_pit=onp.zeros(len(y_data))\n",
        "sig_arr=onp.zeros((len(y_data),n_mixture))\n",
        "mu_arr=onp.zeros((len(y_data),n_mixture))\n",
        "pi_arr=onp.zeros((len(y_data),n_mixture))\n",
        "\n",
        "\n",
        "def gaus(x,pi,mu,sig):\n",
        "  a=-(x-mu)**2/(2*sig**2)\n",
        "  return pi*1/(sig*(2*pi_symb)**0.5)*np.exp(a)\n",
        "\n",
        "def pick(pi,mu,sig):\n",
        "  c=pi.shape[1]\n",
        "  eval=onp.zeros_like(pi)\n",
        "  for i in range(c):\n",
        "    for j in range(c):\n",
        "\n",
        "      eval[:,i]+=gaus(mu[:,i],pi[:,j],mu[:,j],sig[:,j])\n",
        "  return eval\n",
        "\n",
        "\n",
        "loss_arr=np.array([])\n",
        "\n",
        "for b in range(int(len(y_data)/batch_size)):\n",
        "\n",
        "  logmix, mu_data, logstd = get_mdn_coef(the_network(params, x_data[b*batch_size:(b+1)*batch_size,:]))\n",
        "\n",
        "  pi_data = np.exp(logmix)\n",
        "  sigma_data = np.exp(logstd)\n",
        "  k = gumbel_sample(pi_data)\n",
        "  indices = (onp.arange(batch_size), k)\n",
        "  rn = onp.random.randn(batch_size)\n",
        "  sampled=mu_data[np.arange(len(mu_data)),np.argmax(pick(pi_data,mu_data*6,sigma_data*6),axis=1)]\n",
        "  mu_arr[b*batch_size:(b+1)*batch_size,:]=mu_data\n",
        "  sig_arr[b*batch_size:(b+1)*batch_size,:]=sigma_data\n",
        "  pi_arr[b*batch_size:(b+1)*batch_size,:]= pi_data\n",
        "  y_pred[b*batch_size:(b+1)*batch_size]=sampled*6\n",
        "  y_pit[b*batch_size:(b+1)*batch_size]=pit(y_data[b*batch_size:(b+1)*batch_size,0]*6,pi_data,mu_data*6,sigma_data*6)\n",
        "  loss_arr=np.append(loss_arr,(loss_fn(params,x_data[b*batch_size:(b+1)*batch_size,:],y_data[b*batch_size:(b+1)*batch_size,:])))\n",
        "\n",
        "\n",
        "\n",
        "print('PERFORMANCE ON SYNTHETIC DATA')\n",
        "print('       ')\n",
        "print('Average Loss: ',np.mean(loss_arr))\n",
        "print(r'Median delta z /(1+z) ',bias(y_pred,y_data[:,0]*6))\n",
        "print('Overall Sigma_NMAD/(1+z) ',sigma_nmad(y_pred,y_data[:,0]*6))\n",
        "print('Outlier Fraction ',outlier_frac(y_pred,y_data[:,0]*6))\n",
        "print('Median PIT: ', np.median(y_pit))\n",
        "print('        ')\n",
        "\n",
        "bins=np.linspace(0,6,100)\n",
        "import matplotlib as mpl\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.hist2d(y_data[:,0]*6,y_pred,bins=bins,cmap='hot',norm=mpl.colors.LogNorm())\n",
        "plt.xlabel('True Redshift',fontsize=18)\n",
        "plt.ylabel('Photometric Redshift Estimate',fontsize=18)\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "cbar=plt.colorbar()\n",
        "cbar.ax.tick_params(labelsize=16)\n",
        "plt.show()\n",
        "\n",
        "fig, axs = plt.subplots(2, 2,figsize=(16,10))\n",
        "plot=plot_func(bias,y_pred,y_data[:,0]*6,20,6,ax=axs[0,0])\n",
        "axs[0,0].set_ylabel(r'$<\\Delta z /(1+z)>$',fontsize=20)\n",
        "\n",
        "\n",
        "\n",
        "plot=plot_func(sigma_nmad,y_pred,y_data[:,0]*6,20,6,ax=axs[1,0])\n",
        "axs[1,0].set_ylabel(r'$\\sigma_{NMAD}/(1+z)$',fontsize=20)\n",
        "\n",
        "\n",
        "\n",
        "plot=plot_func(outlier_frac,y_pred,y_data[:,0]*6,20,6,ax=axs[0,1])\n",
        "axs[0,1].set_ylabel(r'$\\eta_{0.15}$',fontsize=20)\n",
        "\n",
        "\n",
        "axs[1,1].hist(y_pit,bins=20,edgecolor='black',color='blue')\n",
        "axs[1,1].set_ylabel('Galaxies',fontsize=20)\n",
        "axs[1,1].set_xlabel('PIT',fontsize=20)\n",
        "\n",
        "for tick in axs[1,1].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[1,1].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTss4fC3iAu7"
      },
      "outputs": [],
      "source": [
        "dz=np.absolute((y_pred-y_data[:,0]*6)/(1+y_data[:,0]*6))\n",
        "i=0\n",
        "count=0\n",
        "print(y_pred)\n",
        "while count!=20:\n",
        "  if dz[i]>0.5:  \n",
        "    print(y_pred[i])\n",
        "    plot_pdf(pi_arr[i,:],mu_arr[i,:]*6,sig_arr[i,:]*6,pred=y_pred[i],true=y_data[i,0]*6,zrange=6)\n",
        "    plt.show()\n",
        "    count+=1\n",
        "  i+=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "cat0 = table.Table.read('COSMOS2020.fits',format='fits',hdu=1)\n",
        "\n",
        "spec_cat=cat0\n",
        "n_samples=len(spec_cat)\n",
        "x_spec=onp.zeros((n_samples,n_input))\n",
        "keys=spec_cat.keys()\n",
        "filt_names=onp.array([])\n",
        "y_spec=spec_cat['ZSPEC']\n",
        "count=0\n",
        "for key_name in keys:\n",
        "  if key_name[len(key_name)-4:]=='FLUX':\n",
        "    \n",
        "    filt=key_name[:len(key_name)-5]\n",
        "    filt_names=onp.append(filt_names,filt)\n",
        "    x_spec[:,count]=spec_cat[filt+'_FLUX']\n",
        "    x_spec[:,count+1]=spec_cat[filt+'_FLUXERR']\n",
        "\n",
        "    count+=2\n",
        "\n",
        "spec_cat=0\n",
        "cat0=0\n",
        "\n",
        "\n",
        "y_spec=np.array(y_spec)\n",
        "y_spec=y_spec.reshape(len(y_spec),1)/6\n",
        "x_spec=np.array(x_spec)"
      ],
      "metadata": {
        "id": "yshRgzxI5dw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuM2Tn99mq6H"
      },
      "outputs": [],
      "source": [
        "dz=np.absolute((y_pred-y_data[:,0]*6)/(1+y_data[:,0]*6))\n",
        "\n",
        "print(np.median(np.min(x_data[dz<0.1,:],axis=1)))\n",
        "print(np.median(np.min(x_data[dz>0.1,:],axis=1)))\n",
        "\n",
        "\n",
        "flux=np.array([True,False]*27)\n",
        "error=np.array([False,True]*27)\n",
        "\n",
        "\n",
        "bins=np.linspace(15,35,50)\n",
        "\n",
        "def mag(flux):\n",
        "    x=-2.5*onp.log10(flux) + 23.9 \n",
        "    x[onp.isnan(x)]=-2.5*onp.log10(-flux[onp.isnan(x)]) + 23.9 \n",
        "\n",
        "    return x \n",
        "\n",
        "\n",
        "import matplotlib as mpl\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "plt.hist(mag(np.max(x_data[dz<0.15,:][:,flux],axis=1)),density=True,color='blue',histtype='step',bins=bins,linewidth=3)\n",
        "plt.hist(mag(np.max(x_data[dz>0.15,:][:,flux],axis=1)),density=True,color='red',histtype='step',bins=bins,linewidth=3)\n",
        "plt.hist(mag(np.max(x_spec[:,flux],axis=1)),density=True,color='green',histtype='step',bins=bins,linewidth=3)\n",
        "plt.xlabel('Brightest Band Magnitude',fontsize=16)\n",
        "plt.ylabel('Frequency Density',fontsize=16)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "for i in range(27):\n",
        "  print(i)\n",
        "  plt.figure(figsize=(15,10))\n",
        "  plt.hist(mag(x_data[dz<0.15,2*i]),density=True,color='blue',histtype='step',bins=bins,linewidth=3,label=r'Sythnetic Galaxies $|\\Delta z|/(1+z)<0.15$')\n",
        "  plt.hist(mag(x_data[dz>0.15,2*i]),density=True,color='red',histtype='step',bins=bins,linewidth=3,label=r'Synthetic Galaxies $|\\Delta z|/(1+z)>0.15$ ')\n",
        "  plt.hist(mag(x_spec[:,2*i]),density=True,color='green',histtype='step',bins=bins,linewidth=3,label='COSMOS20 Galaxies')\n",
        "  plt.legend(fontsize=16)\n",
        "  plt.ylabel('Frequency Density',fontsize=16)\n",
        "  plt.xlabel(filter_names[i]+' Magnitude',fontsize=16)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 2,figsize=(16,10))\n",
        "\n",
        "\n",
        "\n",
        "bins=np.linspace(15,35,50)\n",
        "\n",
        "i=2\n",
        "axs[0,0].hist(mag(x_data[dz<0.15,2*i]),density=True,color='blue',histtype='step',bins=bins,linewidth=3,label=r'Sythnetic $|\\Delta z|/(1+z)<0.15$')\n",
        "axs[0,0].hist(mag(x_data[dz>0.15,2*i]),density=True,color='red',histtype='step',bins=bins,linewidth=3,label=r'Synthetic $|\\Delta z|/(1+z)>0.15$ ')\n",
        "axs[0,0].hist(mag(x_spec[:,2*i]),density=True,color='green',histtype='step',bins=bins,linewidth=3,label='COSMOS20')\n",
        "axs[0,0].legend(fontsize=19,loc='upper left',frameon=False)\n",
        "axs[0,0].set_ylabel('Frequency Density',fontsize=20)\n",
        "axs[0,0].set_xlabel(filter_names[i]+' magnitude',fontsize=20)\n",
        "\n",
        "\n",
        "for tick in axs[0,0].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[0,0].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "i=3\n",
        "axs[1,0].hist(mag(x_data[dz<0.15,2*i]),density=True,color='blue',histtype='step',bins=bins,linewidth=3,label=r'Sythnetic Galaxies $|\\Delta z|/(1+z)<0.15$')\n",
        "axs[1,0].hist(mag(x_data[dz>0.15,2*i]),density=True,color='red',histtype='step',bins=bins,linewidth=3,label=r'Synthetic Galaxies $|\\Delta z|/(1+z)>0.15$ ')\n",
        "axs[1,0].hist(mag(x_spec[:,2*i]),density=True,color='green',histtype='step',bins=bins,linewidth=3,label='COSMOS20 Galaxies')\n",
        "\n",
        "axs[1,0].set_ylabel('Frequency Density',fontsize=20)\n",
        "axs[1,0].set_xlabel(filter_names[i]+' magnitude',fontsize=20)\n",
        "\n",
        "\n",
        "for tick in axs[1,0].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[1,0].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "\n",
        "i=4\n",
        "axs[0,1].hist(mag(x_data[dz<0.15,2*i]),density=True,color='blue',histtype='step',bins=bins,linewidth=3,label=r'Sythnetic Galaxies $|\\Delta z|/(1+z)<0.15$')\n",
        "axs[0,1].hist(mag(x_data[dz>0.15,2*i]),density=True,color='red',histtype='step',bins=bins,linewidth=3,label=r'Synthetic Galaxies $|\\Delta z|/(1+z)>0.15$ ')\n",
        "axs[0,1].hist(mag(x_spec[:,2*i]),density=True,color='green',histtype='step',bins=bins,linewidth=3,label='COSMOS20 Galaxies')\n",
        "\n",
        "axs[0,1].set_ylabel('Frequency Density',fontsize=20)\n",
        "axs[0,1].set_xlabel(filter_names[i]+' magnitude',fontsize=20)\n",
        "\n",
        "\n",
        "for tick in axs[0,1].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[0,1].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "\n",
        "i=5\n",
        "axs[1,1].hist(mag(x_data[dz<0.15,2*i]),density=True,color='blue',histtype='step',bins=bins,linewidth=3,label=r'Sythnetic Galaxies $|\\Delta z|/(1+z)<0.15$')\n",
        "axs[1,1].hist(mag(x_data[dz>0.15,2*i]),density=True,color='red',histtype='step',bins=bins,linewidth=3,label=r'Synthetic Galaxies $|\\Delta z|/(1+z)>0.15$ ')\n",
        "axs[1,1].hist(mag(x_spec[:,2*i]),density=True,color='green',histtype='step',bins=bins,linewidth=3,label='COSMOS20 Galaxies')\n",
        "\n",
        "axs[1,1].set_ylabel('Frequency Density',fontsize=20)\n",
        "axs[1,1].set_xlabel(filter_names[i]+' magnitude',fontsize=20)\n",
        "\n",
        "\n",
        "for tick in axs[1,1].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[1,1].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FQeJOrMWf5Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_input=54\n",
        "n_samples =  10000000 # just use train everything in a batch\n",
        "beta=True\n",
        "small_range=False\n",
        "magnitudes=False\n",
        "a=0\n",
        "if beta:\n",
        "  a+=5\n",
        "\n",
        "x_train_data=onp.zeros((n_samples,n_input))\n",
        "y_train_data=onp.zeros(n_samples)\n",
        "\n",
        "cats=int(n_samples/1e6)\n",
        "\n",
        "def mag_err(flux_err,flux):\n",
        "    \n",
        "    return 1.09*flux_err/flux\n",
        "\n",
        "def mag(flux):\n",
        "    x=-2.5*onp.log10(flux) + 23.9 \n",
        "    x[onp.isnan(x)]=0\n",
        "    return x \n",
        "\n",
        "  \n",
        "for c in range(cats):\n",
        "    cat = table.Table.read('sim/mil'+str(c+1)+'_noisy_gal.fits',format='fits',hdu=1)\n",
        "    keys=cat.keys()\n",
        "    count=0\n",
        "    y_train_data[(c)*1000000:(c+1)*1000000]=cat['redshift']\n",
        "    for key_name in keys:\n",
        "\n",
        "        if key_name[len(key_name)-9:]=='BETA_FLUX':\n",
        "\n",
        "                \n",
        "            filt=key_name[:len(key_name)-10+a]\n",
        "\n",
        "            if magnitudes:\n",
        "\n",
        "              x_train_data[(c)*1000000:(c+1)*1000000,count]=mag(cat[filt+'_FLUX'])\n",
        "              x_train_data[(c)*1000000:(c+1)*1000000,count+1]=mag_err(cat[filt+'_FLUXERR'],cat[filt+'_FLUX'])\n",
        "            else:\n",
        "              x_train_data[(c)*1000000:(c+1)*1000000,count]=cat[filt+'_FLUX']\n",
        "              x_train_data[(c)*1000000:(c+1)*1000000,count+1]=cat[filt+'_FLUXERR']\n",
        "            \n",
        "            count+=2\n",
        "            \n",
        "            \n",
        "        \n",
        "    print(c)\n",
        "\n",
        "\n",
        "x_train_data = np.array(x_train_data.reshape(n_samples, n_input))\n",
        "\n",
        "\n",
        "y_train_data = np.array(y_train_data.reshape(len(y_train_data), 1))/6\n",
        "\n",
        "cat=0\n",
        "\n"
      ],
      "metadata": {
        "id": "NZ-aejJsvqGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mag_err(flux_err,flux):\n",
        "    \n",
        "    return np.absolute(1.09*flux_err/flux)\n",
        "\n",
        "def mag(flux):\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    x=-2.5*onp.log10(flux) + 23.9 \n",
        "    x[onp.isnan(x)]=-2.5*onp.log10(-flux[onp.isnan(x)]) + 23.9 \n",
        "    return x \n",
        "\n",
        "def importance_hist(test_gal,training_gals,training_redshift,ax=None):\n",
        "\n",
        "  flux=np.array([True,False]*27)\n",
        "  error=np.array([False,True]*27)\n",
        "\n",
        "  test_mag=mag(test_gal[:,flux])\n",
        "  train_mag=mag(training_gals[:,flux])\n",
        "  train_error=mag_err(training_gals[:,error],test_gal[:,flux])\n",
        "  \n",
        "\n",
        "  log_weights= -np.sum(np.log(train_error),axis=1)- 0.5 *np.sum(((test_mag-train_mag)/train_error)**2,axis=1)\n",
        "\n",
        "  frq, edges = np.histogram(training_redshift.reshape(len(training_redshift),), bins=50, weights=np.exp(log_weights), density=True)\n",
        "  if ax!=None:\n",
        "    the_plot=ax.bar(edges[:-1]*6, frq, width=np.diff(edges)*6, edgecolor=\"black\", align=\"edge\",color='blue')\n",
        "  else:\n",
        "    the_plot=plt.bar(edges[:-1]*6, frq, width=np.diff(edges)*6, edgecolor=\"black\", align=\"edge\")\n",
        "\n",
        "  return the_plot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ids=np.where(np.logical_and(dz>0.045,dz<0.05))[0]\n",
        "\n",
        "for i in range(1):\n",
        "  select_id=ids[i]\n",
        "  print(i)\n",
        "  print(dz[select_id])\n",
        "  test_gal=x_data[select_id,:].reshape(1,54)\n",
        "\n",
        "\n",
        "  fig, axs = plt.subplots(2, 1,sharex=True,figsize=(6,8))\n",
        "\n",
        "  logmix, mu_data, logstd = get_mdn_coef(the_network(params,test_gal))\n",
        "  \n",
        "  pi_data = np.exp(logmix)\n",
        "  sigma_data = np.exp(logstd)\n",
        "  sampled=mu_data[np.arange(len(mu_data)),np.argmax(pick(pi_data,mu_data*6,sigma_data*6),axis=1)]\n",
        "\n",
        "  importance_hist(test_gal,x_train_data,y_train_data,ax=axs[1])\n",
        "\n",
        "  plot_pdf(pi_data[0,:],mu_data[0,:]*6,sigma_data[0,:]*6,pred=sampled[0]*6,true=y_data[select_id,0]*6,zrange=6,ax=axs[0])\n",
        "  fig.subplots_adjust(hspace=0)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CMzH0QKARN-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, axs = plt.subplots(3, 2,sharex=True,figsize=(20,16))\n",
        "\n",
        "ids=np.where(dz<0.05)[0]\n",
        "\n",
        "select_id=ids[4]\n",
        "print(dz[select_id])\n",
        "test_gal=x_data[select_id,:].reshape(1,54)\n",
        "\n",
        "logmix, mu_data, logstd = get_mdn_coef(the_network(params,test_gal))\n",
        "  \n",
        "pi_data = np.exp(logmix)\n",
        "sigma_data = np.exp(logstd)\n",
        "sampled=mu_data[np.arange(len(mu_data)),np.argmax(pick(pi_data,mu_data*6,sigma_data*6),axis=1)]\n",
        "\n",
        "importance_hist(test_gal,x_train_data,y_train_data,ax=axs[0,1])\n",
        "\n",
        "plot_pdf(pi_data[0,:],mu_data[0,:]*6,sigma_data[0,:]*6,pred=sampled[0]*6,true=y_data[select_id,0]*6,zrange=6,ax=axs[0,0])\n",
        "\n",
        "ids=np.where(np.logical_and(dz>0.045,dz<0.05))[0]\n",
        "\n",
        "select_id=ids[30]\n",
        "print(dz[select_id])\n",
        "test_gal=x_data[select_id,:].reshape(1,54)\n",
        "\n",
        "logmix, mu_data, logstd = get_mdn_coef(the_network(params,test_gal))\n",
        "  \n",
        "pi_data = np.exp(logmix)\n",
        "sigma_data = np.exp(logstd)\n",
        "sampled=mu_data[np.arange(len(mu_data)),np.argmax(pick(pi_data,mu_data*6,sigma_data*6),axis=1)]\n",
        "\n",
        "importance_hist(test_gal,x_train_data,y_train_data,ax=axs[1,1])\n",
        "\n",
        "plot_pdf(pi_data[0,:],mu_data[0,:]*6,sigma_data[0,:]*6,pred=sampled[0]*6,true=y_data[select_id,0]*6,zrange=6,ax=axs[1,0])\n",
        "\n",
        "\n",
        "ids=np.where(dz>0.15)[0]\n",
        "\n",
        "select_id=ids[67]\n",
        "print(dz[select_id])\n",
        "test_gal=x_data[select_id,:].reshape(1,54)\n",
        "\n",
        "logmix, mu_data, logstd = get_mdn_coef(the_network(params,test_gal))\n",
        "\n",
        "pi_data = np.exp(logmix)\n",
        "sigma_data = np.exp(logstd)\n",
        "sampled=mu_data[np.arange(len(mu_data)),np.argmax(pick(pi_data,mu_data*6,sigma_data*6),axis=1)]\n",
        "importance_hist(test_gal,x_train_data,y_train_data,ax=axs[2,1])\n",
        "plot_pdf(pi_data[0,:],mu_data[0,:]*6,sigma_data[0,:]*6,pred=sampled[0]*6,true=y_data[select_id,0]*6,zrange=6,ax=axs[2,0])\n",
        "\n",
        "\n",
        "fig.subplots_adjust(hspace=0)\n",
        "\n",
        "\n",
        "axs[2,0].set_xlabel(r'Redshift $z$',fontsize=20)\n",
        "axs[0,0].set_ylabel(r'$p(z|x)$',fontsize=20)\n",
        "axs[1,0].set_ylabel(r'$p(z|x)$',fontsize=20)\n",
        "axs[2,0].set_ylabel(r'$p(z|x)$',fontsize=20)\n",
        "\n",
        "axs[2,1].set_xlabel(r'Redshift $z$',fontsize=20)\n",
        "axs[0,1].set_ylabel(r'Weighted Frequency',fontsize=20)\n",
        "axs[1,1].set_ylabel(r'Weighted Frequency',fontsize=20)\n",
        "axs[2,1].set_ylabel(r'Weighted Frequency',fontsize=20)\n",
        "\n",
        "\n",
        "axs[1,0].set_ylim(0,1.19)\n",
        "axs[1,1].set_ylim(0,29.9)\n",
        "\n",
        "\n",
        "for tick in axs[2,0].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[2,1].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "for tick in axs[0,0].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[1,0].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[2,0].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "for tick in axs[0,1].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[1,1].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[2,1].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "axs[0,0].legend(fontsize=20)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "q2MHm1xpDUlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXwiKpKV4ayz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#x_data=0\n",
        "#y_data=0\n",
        "cat0 = table.Table.read('COSMOS2020.fits',format='fits',hdu=1)\n",
        "#cat0 = cat0[cat0['lp_zq']>0]\n",
        "spec_cat=cat0[cat0['ZSPEC']!=-1]\n",
        "#spec_cat=spec_cat[spec_cat['ZSPEC']<2]\n",
        "#spec_cat=cat0\n",
        "n_samples=len(spec_cat)\n",
        "x_spec=onp.zeros((n_samples,n_input))\n",
        "keys=spec_cat.keys()\n",
        "filt_names=onp.array([])\n",
        "y_spec=spec_cat['ZSPEC']\n",
        "count=0\n",
        "for key_name in keys:\n",
        "  if key_name[len(key_name)-4:]=='FLUX':\n",
        "    \n",
        "    filt=key_name[:len(key_name)-5]\n",
        "    filt_names=onp.append(filt_names,filt)\n",
        "    x_spec[:,count]=spec_cat[filt+'_FLUX']\n",
        "    x_spec[:,count+1]=spec_cat[filt+'_FLUXERR']\n",
        "\n",
        "    count+=2\n",
        "\n",
        "#spec_cat=0\n",
        "#cat0=0\n",
        "\n",
        "\n",
        "y_spec=np.array(y_spec)\n",
        "y_spec=y_spec.reshape(len(y_spec),1)/6\n",
        "x_spec=np.array(x_spec)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fE9g2OBJR7fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXoPIP5XVbBk"
      },
      "outputs": [],
      "source": [
        "!pip install jaxopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-l5KbUC1hoB"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "pi_symb=math.pi\n",
        "def gaus(x,pi,mu,sig):\n",
        "  a=-(x-mu)**2/(2*sig**2)\n",
        "  return pi*1/(sig*(2*pi_symb)**0.5)*np.exp(a)\n",
        "\n",
        "def pick(pi,mu,sig):\n",
        "  c=pi.shape[1]\n",
        "  eval=onp.zeros_like(pi)\n",
        "  for i in range(c):\n",
        "    for j in range(c):\n",
        "\n",
        "      eval[:,i]+=gaus(mu[:,i],pi[:,j],mu[:,j],sig[:,j])\n",
        "  return eval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe2zyXYBSOsq"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from numpy.ma.core import add\n",
        "from jaxopt import ScipyBoundedMinimize as minimize\n",
        "\n",
        "\n",
        "x_spec = np.array(x_spec.reshape(n_samples, n_input))\n",
        "y_spec = np.array(y_spec.reshape(n_samples, 1))\n",
        "\n",
        "import copy \n",
        "\n",
        "alpha_mask=onp.identity(54)\n",
        "beta_mask=onp.identity(54)\n",
        "\n",
        "one_col= onp.zeros((len(x_spec),54))\n",
        "two_col= onp.zeros((len(x_spec),54))\n",
        "x_spec_flux=onp.zeros((len(x_spec),54))\n",
        "\n",
        "for i in range(27):\n",
        "  alpha_mask[2*i+1,2*i+1]=0\n",
        "  beta_mask[2*i,2*i]=0\n",
        "  one_col[:,2*i]=1\n",
        "  two_col[:,2*i+1]=1\n",
        "  x_spec_flux[:,2*i+1]=copy.deepcopy(x_spec[:,2*i])\n",
        "\n",
        "\n",
        "alpha_mask=np.array(alpha_mask)\n",
        "beta_mask=np.array(beta_mask)\n",
        "one_col=np.array(one_col)\n",
        "two_col=np.array(two_col)\n",
        "x_spec_flux=np.array(x_spec_flux)\n",
        "\n",
        "def add_cal(p0,x_data):\n",
        "  the_params_1d=p0.reshape(1,54)\n",
        "\n",
        "  the_params= np.repeat(the_params_1d, repeats=len(x_spec), axis=0)\n",
        "\n",
        "  params_shift=the_params.at[:,1:].set(the_params[:,:53])\n",
        "  \n",
        "  alpha_flux=np.dot(the_params,alpha_mask)+two_col\n",
        "  beta_err=np.dot(the_params,beta_mask)\n",
        "  alpha_err=np.dot(params_shift,beta_mask) +one_col\n",
        "\n",
        "\n",
        "  x_corr=copy.deepcopy(x_spec)\n",
        "  x_corr= ((x_corr*alpha_err)**2 + (beta_err*alpha_err*x_spec_flux)**2)**0.5\n",
        "\n",
        "  x_corr=x_corr*alpha_flux\n",
        "\n",
        "\n",
        "  return x_corr\n",
        "  \n",
        "\n",
        "ans=6*y_spec.reshape(len(y_spec),)\n",
        "def opt_func(opt_params):\n",
        "  loss_val=loss_fn(params, add_cal(opt_params,x_spec), y_spec)\n",
        "  return loss_val\n",
        "def sig_func(opt_params):\n",
        "  logmix, mu_data, logstd = get_mdn_coef(the_network(params, add_cal(opt_params,x_spec)))\n",
        "  pi_data = softmax(logmix)\n",
        "  sigma_data = np.exp(logstd)\n",
        "\n",
        "  y_pred=mu_data[np.arange(len(mu_data)),np.argmax(pick(pi_data,mu_data*6,sigma_data*6),axis=1)]*6\n",
        "\n",
        "  sort=np.sort((y_pred-ans)/(1+ans))\n",
        "\n",
        "  return (sort[int(0.841*len(x_spec))-1]-sort[int(0.159*len(x_spec))-1])*0.5\n",
        "\n",
        "\n",
        "alpha_bound0=[0.8,1.2]\n",
        "beta_bound0=[0.0,0.0]\n",
        "\n",
        "lower_bounds=onp.array([])\n",
        "upper_bounds=onp.array([])\n",
        "for i in range(27):\n",
        "\n",
        "  if i != 4:\n",
        "\n",
        "    lower_bounds=onp.append(lower_bounds,alpha_bound0[0])\n",
        "    lower_bounds=onp.append(lower_bounds,beta_bound0[0])\n",
        "\n",
        "    upper_bounds=onp.append(upper_bounds,alpha_bound0[1])\n",
        "    upper_bounds=onp.append(upper_bounds,beta_bound0[1])\n",
        "\n",
        "  else:\n",
        "\n",
        "    lower_bounds=onp.append(lower_bounds,1.0)\n",
        "    lower_bounds=onp.append(lower_bounds,beta_bound0[0])\n",
        "\n",
        "    upper_bounds=onp.append(upper_bounds,1.0)\n",
        "    upper_bounds=onp.append(upper_bounds,beta_bound0[1])\n",
        "\n",
        "\n",
        "bounds = (np.array(lower_bounds), np.array(upper_bounds))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "best_score=loss_fn(params, x_spec, y_spec)\n",
        "print(best_score)\n",
        "for i in range(50):\n",
        "\n",
        "  p0=np.array([])\n",
        "  for k in range(27):\n",
        "\n",
        "    if k!=4:\n",
        "      p0=np.append(p0,0.8+onp.random.random()*0.4)\n",
        "    else:\n",
        "      p0=np.append(p0,1.0)\n",
        "    p0=np.append(p0,0.)\n",
        "\n",
        "  \n",
        "  p0=p0.reshape(54,)\n",
        "\n",
        "  tol = 1e-4\n",
        "  method = 'SLSQP' #'L-BFGS-B' \n",
        "  options = {'disp':False,'ftol':tol, 'gtol':tol}\n",
        "  opt = minimize(fun=opt_func,method=method, tol=tol,options=options,maxiter=100000)\n",
        "  opt_params,_=opt.run(p0,bounds=bounds)\n",
        "  #score= loss_fn(params, add_cal(opt_params,x_spec), y_spec)\n",
        "  score=opt_func(opt_params)\n",
        "  if score<best_score:\n",
        "    best_params=copy.deepcopy(opt_params)\n",
        "    best_score=score\n",
        "    print(score)\n",
        "    print('sig:', sig_func(best_params))\n",
        "    \n",
        "print(best_score)\n",
        "print(best_params)\n",
        "\n",
        "p0=onp.array(best_params)\n",
        "\n",
        "beta_bound0=[0,0.1]\n",
        "\n",
        "lower_bounds=onp.array([])\n",
        "upper_bounds=onp.array([])\n",
        "for i in range(27):\n",
        "\n",
        "  if i != 4:\n",
        "\n",
        "    lower_bounds=onp.append(lower_bounds,alpha_bound0[0])\n",
        "    lower_bounds=onp.append(lower_bounds,beta_bound0[0])\n",
        "\n",
        "    upper_bounds=onp.append(upper_bounds,alpha_bound0[1])\n",
        "    upper_bounds=onp.append(upper_bounds,beta_bound0[1])\n",
        "\n",
        "  else:\n",
        "\n",
        "    lower_bounds=onp.append(lower_bounds,1.0)\n",
        "    lower_bounds=onp.append(lower_bounds,beta_bound0[0])\n",
        "\n",
        "    upper_bounds=onp.append(upper_bounds,1.0)\n",
        "    upper_bounds=onp.append(upper_bounds,beta_bound0[1])\n",
        "\n",
        "\n",
        "bounds = (np.array(lower_bounds), np.array(upper_bounds))\n",
        "\n",
        "for k in range(50):\n",
        "  for i in range(27):\n",
        "    p0[2*i+1]=onp.random.random()*0.1\n",
        "  tol = 1e-4\n",
        "  method = 'SLSQP' #'L-BFGS-B' \n",
        "  options = {'disp':False,'ftol':tol, 'gtol':tol}\n",
        "  opt = minimize(fun=opt_func,method=method, tol=tol,maxiter=1000000)\n",
        "  opt_params,_=opt.run(np.array(p0),bounds=bounds)\n",
        "  score=opt_func(opt_params)\n",
        "  #score= loss_fn(params, add_cal(best_params,x_spec), y_spec)\n",
        "  if score<best_score:\n",
        "    best_params=copy.deepcopy(opt_params)\n",
        "    best_score=score\n",
        "    print(score)\n",
        "    print('sig:', sig_func(best_params))\n",
        "print(best_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params=np.load('mdn_best_calib.npy',allow_pickle=True)"
      ],
      "metadata": {
        "id": "58XbCxt1Bc1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCuVmPNeSxyV"
      },
      "outputs": [],
      "source": [
        "\n",
        "logmix, mu_data, logstd = get_mdn_coef(the_network(params, x_spec))\n",
        "pi_data = softmax(logmix)\n",
        "sigma_data = np.exp(logstd)\n",
        "k = gumbel_sample(pi_data)\n",
        "indices = (onp.arange(len(x_spec)), k)\n",
        "rn = onp.random.randn(len(x_spec))\n",
        "#sampled = rn * sigma_data[indices] + mu_data[indices]\n",
        "sampled=mu_data[np.arange(len(mu_data)),np.argmax(pick(pi_data,mu_data*6,sigma_data*6),axis=1)]*6\n",
        "\n",
        "y_pred_before=copy.deepcopy(sampled)\n",
        "y_pit_before=pit(y_spec[:,0]*6,pi_data,mu_data*6,sigma_data*6)\n",
        "\n",
        "loss=loss_fn(params, x_spec, y_spec)\n",
        "\n",
        "print('RESULTS BEFORE CALLIBRATION')\n",
        "print('         ')\n",
        "print('Average Loss: ',loss)\n",
        "print(r'Median delta z /(1+z) ',bias(y_pred_before,y_spec[:,0]*6))\n",
        "print('Overall Sigma_NMAD/(1+z) ',sigma_nmad(y_pred_before,y_spec[:,0]*6))\n",
        "print('Outlier Fraction ',outlier_frac(y_pred_before,y_spec[:,0]*6))\n",
        "print('Median PIT: ', np.median(y_pit_before))\n",
        "print('        ')\n",
        "\n",
        "\n",
        "\n",
        "logmix, mu_data, logstd = get_mdn_coef(the_network(params, add_cal(best_params,x_spec)))\n",
        "pi_data = softmax(logmix)\n",
        "sigma_data = np.exp(logstd)\n",
        "k = gumbel_sample(pi_data)\n",
        "indices = (onp.arange(len(x_spec)), k)\n",
        "rn = onp.random.randn(len(x_spec))\n",
        "#sampled = rn * sigma_data[indices] + mu_data[indices]\n",
        "sampled=mu_data[np.arange(len(mu_data)),np.argmax(pick(pi_data,mu_data*6,sigma_data*6),axis=1)]*6\n",
        "\n",
        "y_pred=copy.deepcopy(sampled)\n",
        "y_pit=pit(y_spec[:,0]*6,pi_data,mu_data*6,sigma_data*6)\n",
        "\n",
        "loss=loss_fn(params,add_cal(best_params,x_spec), y_spec)\n",
        "\n",
        "print('RESULTS AFTER CALLIBRATION')\n",
        "print('         ')\n",
        "print('Average Loss: ',loss)\n",
        "print(r'Median delta z /(1+z) ',bias(y_pred,y_spec[:,0]*6))\n",
        "print('Overall Sigma_NMAD/(1+z) ',sigma_nmad(y_pred,y_spec[:,0]*6))\n",
        "print('Outlier Fraction ',outlier_frac(y_pred,y_spec[:,0]*6))\n",
        "print('Median PIT: ', np.median(y_pit))\n",
        "print('        ')\n",
        "\n",
        "bins=np.linspace(0,6,100)\n",
        "import matplotlib as mpl\n",
        "plt.figure(figsize=(14,10))\n",
        "plt.hist2d(y_spec[:,0]*6,y_pred,bins=bins,cmap='hot',norm=mpl.colors.LogNorm())\n",
        "plt.xlabel('Spectroscopic Redshift',fontsize=18)\n",
        "plt.ylabel('Photometric Redshift Estimate',fontsize=18)\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "cbar=plt.colorbar()\n",
        "cbar.ax.tick_params(labelsize=16)\n",
        "plt.show()\n",
        "\n",
        "fig, axs = plt.subplots(2, 2,figsize=(16,10))\n",
        "plot=plot_func(bias,y_pred_before,y_spec[:,0]*6,20,6,ax=axs[0,0],color='red',label='Before Calibration')\n",
        "plot=plot_func(bias,y_pred,y_spec[:,0]*6,20,6,ax=axs[0,0],color='blue',label='After Calibration')\n",
        "axs[0,0].set_ylabel(r'$<\\Delta z /(1+z)>$',fontsize=20)\n",
        "axs[0,0].legend(fontsize=20)\n",
        "\n",
        "plot=plot_func(sigma_nmad,y_pred_before,y_spec[:,0]*6,20,6,ax=axs[1,0],color='red')\n",
        "plot=plot_func(sigma_nmad,y_pred,y_spec[:,0]*6,20,6,ax=axs[1,0],color='blue')\n",
        "axs[1,0].set_ylabel(r'$\\sigma_{NMAD}/(1+z)$',fontsize=20)\n",
        "\n",
        "\n",
        "\n",
        "plot=plot_func(outlier_frac,y_pred_before,y_spec[:,0]*6,20,6,ax=axs[0,1],color='red')\n",
        "plot=plot_func(outlier_frac,y_pred,y_spec[:,0]*6,20,6,ax=axs[0,1],color='blue')\n",
        "axs[0,1].set_ylabel(r'$\\eta_{0.15}$',fontsize=20)\n",
        "\n",
        "axs[1,1].hist(y_pit_before,bins=20,color='red',histtype='step',linewidth=2)\n",
        "axs[1,1].hist(y_pit,bins=20,color='blue',histtype='step',linewidth=2)\n",
        "axs[1,1].set_ylabel('Galaxies',fontsize=20)\n",
        "axs[1,1].set_xlabel('PIT',fontsize=20)\n",
        "axs[1,1].set_ylim(100,10000)\n",
        "axs[1,1].set_yscale('log')\n",
        "for tick in axs[1,1].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[1,1].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exVGMYPLXXrr"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, axs = plt.subplots(2, 2,sharex=True,figsize=(16,8))\n",
        "ax_id=[[0,0],[0,1],[1,0],[1,1]]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "id_arr=[6154,5842,1395,8652]\n",
        "\n",
        "\n",
        "for i in range(4):\n",
        "  the_ax_id=ax_id[i]\n",
        "\n",
        "  plot_pdf(pi_data[id_arr[i],:],mu_data[id_arr[i],:]*6,sigma_data[id_arr[i],:]*6,pred=sampled[id_arr[i]],true=y_spec[id_arr[i],0]*6,zrange=6,ax=axs[the_ax_id[0],the_ax_id[1]])\n",
        "\n",
        "\n",
        "fig.subplots_adjust(hspace=0)\n",
        "\n",
        "\n",
        "axs[1,0].set_xlabel(r'Redshift $z$',fontsize=20)\n",
        "axs[0,0].set_ylabel(r'$p(z|x)$',fontsize=20)\n",
        "axs[1,0].set_ylabel(r'$p(z|x)$',fontsize=20)\n",
        "\n",
        "axs[1,1].set_xlabel(r'Redshift $z$',fontsize=20)\n",
        "axs[0,1].set_ylabel(r'$p(z|x)$',fontsize=20)\n",
        "axs[1,1].set_ylabel(r'$p(z|x)$',fontsize=20)\n",
        "\n",
        "\n",
        "for tick in axs[1,0].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[1,1].xaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "for tick in axs[0,0].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[1,0].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "for tick in axs[0,1].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "for tick in axs[1,1].yaxis.get_major_ticks():\n",
        "    tick.label.set_fontsize(18) \n",
        "\n",
        "axs[0,0].legend(fontsize=20)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "cat0 = table.Table.read('COSMOS2020.fits',format='fits',hdu=1)\n",
        "cat0 = cat0[cat0['lp_zq']>0]\n",
        "n_samples=len(cat0)\n",
        "x_data=onp.zeros((n_samples,n_input))\n",
        "keys=cat0.keys()\n",
        "filt_names=onp.array([])\n",
        "count=0\n",
        "for key_name in keys:\n",
        "  if key_name[len(key_name)-4:]=='FLUX':\n",
        "    \n",
        "    filt=key_name[:len(key_name)-5]\n",
        "    filt_names=onp.append(filt_names,filt)\n",
        "    x_data[:,count]=cat0[filt+'_FLUX']\n",
        "    x_data[:,count+1]=cat0[filt+'_FLUXERR']\n",
        "\n",
        "    count+=2\n"
      ],
      "metadata": {
        "id": "CN82OiKMC46j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params=np.load('mdn_best_calib.npy',allow_pickle=True)\n",
        "\n",
        "import copy \n",
        "\n",
        "\n",
        "def add_cal(p0,x_data):\n",
        "\n",
        "  alpha_mask=onp.identity(54)\n",
        "  beta_mask=onp.identity(54)\n",
        "\n",
        "  one_col= onp.zeros((len(x_data),54))\n",
        "  two_col= onp.zeros((len(x_data),54))\n",
        "  x_data_flux=onp.zeros((len(x_data),54))\n",
        "\n",
        "  for i in range(27):\n",
        "    alpha_mask[2*i+1,2*i+1]=0\n",
        "    beta_mask[2*i,2*i]=0\n",
        "    one_col[:,2*i]=1\n",
        "    two_col[:,2*i+1]=1\n",
        "    x_data_flux[:,2*i+1]=copy.deepcopy(x_data[:,2*i])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  alpha_mask=np.array(alpha_mask)\n",
        "  beta_mask=np.array(beta_mask)\n",
        "  one_col=np.array(one_col)\n",
        "  two_col=np.array(two_col)\n",
        "  x_data_flux=np.array(x_data_flux)\n",
        "  the_params_1d=p0.reshape(1,54)\n",
        "\n",
        "  the_params= np.repeat(the_params_1d, repeats=len(x_data), axis=0)\n",
        "\n",
        "  params_shift=the_params.at[:,1:].set(the_params[:,:53])\n",
        "  \n",
        "  alpha_flux=np.dot(the_params,alpha_mask)+two_col\n",
        "  beta_err=np.dot(the_params,beta_mask)\n",
        "  alpha_err=np.dot(params_shift,beta_mask) +one_col\n",
        "\n",
        "\n",
        "  x_corr=copy.deepcopy(x_data)\n",
        "  x_corr= ((x_corr*alpha_err)**2 + (beta_err*alpha_err*x_data_flux)**2)**0.5\n",
        "\n",
        "  x_corr=x_corr*alpha_flux\n",
        "\n",
        "\n",
        "  return x_corr"
      ],
      "metadata": {
        "id": "LO9zDIqyG1Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import math\n",
        "pi_symb=math.pi\n",
        "\n",
        "y_pred=onp.zeros(len(x_data))\n",
        "y_pit=onp.zeros(len(x_data))\n",
        "sig_arr=onp.zeros((len(x_data),n_mixture))\n",
        "mu_arr=onp.zeros((len(x_data),n_mixture))\n",
        "pi_arr=onp.zeros((len(x_data),n_mixture))\n",
        "def ceildiv(a, b):\n",
        "    return -(a // -b)\n",
        "\n",
        "def gaus(x,pi,mu,sig):\n",
        "  a=-(x-mu)**2/(2*sig**2)\n",
        "  return pi*1/(sig*(2*pi_symb)**0.5)*np.exp(a)\n",
        "\n",
        "def pick(pi,mu,sig):\n",
        "  c=pi.shape[1]\n",
        "  eval=onp.zeros_like(pi)\n",
        "  for i in range(c):\n",
        "    for j in range(c):\n",
        "\n",
        "      eval[:,i]+=gaus(mu[:,i],pi[:,j],mu[:,j],sig[:,j])\n",
        "  return eval\n",
        "\n",
        "\n",
        "loss_arr=np.array([])\n",
        "batch_size=100000\n",
        "for b in range(int(ceildiv(len(x_data),batch_size))):\n",
        "\n",
        "  logmix, mu_data, logstd = get_mdn_coef(the_network(params, add_cal(best_params,x_data[b*batch_size:(b+1)*batch_size,:])))\n",
        "\n",
        "  pi_data = np.exp(logmix)\n",
        "  sigma_data = np.exp(logstd)\n",
        "  k = gumbel_sample(pi_data)\n",
        "  indices = (onp.arange(batch_size), k)\n",
        "  rn = onp.random.randn(batch_size)\n",
        "  sampled=mu_data[np.arange(len(mu_data)),np.argmax(pick(pi_data,mu_data*6,sigma_data*6),axis=1)]\n",
        "  mu_arr[b*batch_size:(b+1)*batch_size,:]=mu_data\n",
        "  sig_arr[b*batch_size:(b+1)*batch_size,:]=sigma_data\n",
        "  pi_arr[b*batch_size:(b+1)*batch_size,:]= pi_data\n",
        "  y_pred[b*batch_size:(b+1)*batch_size]=sampled*6\n",
        "  \n",
        "  if b ==0:\n",
        "    x=np.linspace(0,6,1200)\n",
        "    pdf_arr=onp.zeros((50000,1200))\n",
        "    for i in range(50000):\n",
        "      pdf=np.zeros(1200)\n",
        "      for j in range(3):\n",
        "              pdf+=pi_data[i,j]*stats.norm.pdf(x,6*mu_data[i,j],6*sigma_data[i,j])\n",
        "\n",
        "      pdf_arr[i,:]=pdf\n",
        "\n",
        "      if i%1000==0:\n",
        "        print(i)\n",
        "\n",
        "    np.save('mdn_phot_pdf.npy',pdf_arr,allow_pickle=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xpqb-4g-DRCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "MDN_COSMOS_Test.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}